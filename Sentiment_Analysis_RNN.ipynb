{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment_Analysis_RNN.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SamuelaAnastasi/RNN_Sentiment_Analysis/blob/master/Sentiment_Analysis_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5_W3AptCHNe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4ZtWgknGQ5O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# read txt files of reviews and labels\n",
        "with open('/gdrive/My Drive/Colab Notebooks/sentiment_analysis/data/reviews.txt', 'r') as f:\n",
        "  reviews = f.read()\n",
        "with open('/gdrive/My Drive/Colab Notebooks/sentiment_analysis/data/labels.txt', 'r') as f:\n",
        "  labels = f.read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6RxsuHAHumU",
        "colab_type": "code",
        "outputId": "b4c2b877-b90c-4357-be94-18fdc49600cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "print(reviews[:200])\n",
        "print()\n",
        "print(labels[:26])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bromwell high is a cartoon comedy . it ran at the same time as some other programs about school life  such as  teachers  . my   years in the teaching profession lead me to believe that bromwell high  \n",
            "\n",
            "positive\n",
            "negative\n",
            "positive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRPHmfRjJiCG",
        "colab_type": "code",
        "outputId": "1f970ebc-f55a-4873-f09e-964486e997ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#preprocess and tokenize text data\n",
        "#convert to lowercase \n",
        "#clean data: remove punctuation\n",
        "from string import punctuation \n",
        "\n",
        "#string.punctuation python 3.0\n",
        "print(punctuation)\n",
        "\n",
        "reviews = reviews.lower()\n",
        "clean_reviews = ''.join([c for c in reviews if c not in punctuation])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3T2lT9xTMVDY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#clean data: remove \\n chars that separates reviews from each-other\n",
        "# split clean reviews by \\n and join them again\n",
        "reviews_split = clean_reviews.split('\\n')\n",
        "clean_reviews = ' '.join(reviews_split)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WcTTOnGNObQ",
        "colab_type": "code",
        "outputId": "b3635769-31d0-483f-fc17-d5b29a3fdef5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "#create list of all words in cleaned reviews and print some of them\n",
        "words = clean_reviews.split()\n",
        "words[:20]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['bromwell',\n",
              " 'high',\n",
              " 'is',\n",
              " 'a',\n",
              " 'cartoon',\n",
              " 'comedy',\n",
              " 'it',\n",
              " 'ran',\n",
              " 'at',\n",
              " 'the',\n",
              " 'same',\n",
              " 'time',\n",
              " 'as',\n",
              " 'some',\n",
              " 'other',\n",
              " 'programs',\n",
              " 'about',\n",
              " 'school',\n",
              " 'life',\n",
              " 'such']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkPvZyvfOCC3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#encode each word and label as int\n",
        "# create a dict that maps each unique word to int vals\n",
        "# subclass of dict: counts the hashtable object \n",
        "#creates a dict that maps obj to the n of times they apear in the input \n",
        "from collections import Counter\n",
        "\n",
        "#create dict of words where most frequent words are assigned lowest int vals\n",
        "w_counts = Counter(words)\n",
        "w_sorted = sorted(w_counts, key=w_counts.get, reverse=True)\n",
        "# vocab = sorted(counts, key=counts.get, reverse=True)\n",
        "#create dict and assign 1 to most frequent word\n",
        "w_to_int = {word: i for i, word in enumerate(w_sorted, 1)}\n",
        "\n",
        "# create a list that will contain all int values assigned to each word for each review\n",
        "reviews_ints = []\n",
        "# get each review in reviews previously splitted by \\n\n",
        "for review in reviews_split:\n",
        "  #then for each word in this review get the int val from the w_to_int dict\n",
        "  #and append it to the reviews_ints. \n",
        "  #Now each word in each review is stored as int inside reviews_ints\n",
        "  reviews_ints.append([w_to_int[word] for word in review.split()])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vwovLugclAD",
        "colab_type": "text"
      },
      "source": [
        "###Test data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbCjyr9HcogZ",
        "colab_type": "code",
        "outputId": "7a2e601b-dd15-4519-837f-186d2504209a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "# stats about vocabulary\n",
        "print('Unique words: ', len((w_to_int)))  # should ~ 74000+\n",
        "print()\n",
        "\n",
        "# print tokens in first review\n",
        "print('Tokenized review: \\n', reviews_ints[:1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique words:  74072\n",
            "\n",
            "Tokenized review: \n",
            " [[21025, 308, 6, 3, 1050, 207, 8, 2138, 32, 1, 171, 57, 15, 49, 81, 5785, 44, 382, 110, 140, 15, 5194, 60, 154, 9, 1, 4975, 5852, 475, 71, 5, 260, 12, 21025, 308, 13, 1978, 6, 74, 2395, 5, 613, 73, 6, 5194, 1, 24103, 5, 1983, 10166, 1, 5786, 1499, 36, 51, 66, 204, 145, 67, 1199, 5194, 19869, 1, 37442, 4, 1, 221, 883, 31, 2988, 71, 4, 1, 5787, 10, 686, 2, 67, 1499, 54, 10, 216, 1, 383, 9, 62, 3, 1406, 3686, 783, 5, 3483, 180, 1, 382, 10, 1212, 13583, 32, 308, 3, 349, 341, 2913, 10, 143, 127, 5, 7690, 30, 4, 129, 5194, 1406, 2326, 5, 21025, 308, 10, 528, 12, 109, 1448, 4, 60, 543, 102, 12, 21025, 308, 6, 227, 4146, 48, 3, 2211, 12, 8, 215, 23]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1jq7neDfL3f",
        "colab_type": "text"
      },
      "source": [
        "###Convert labels\n",
        "Labels have values positive and negative that should be converted to 1 and 0 respectively"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDD4-2ereyzh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#convert labels to be all 1 and 0 \n",
        "# 1=positive, 0=negative label conversion\n",
        "labels_split = labels.split('\\n')\n",
        "encoded_labels = np.array([1 if label == 'positive' else 0 for label in labels_split])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNeTRUt5ihKg",
        "colab_type": "text"
      },
      "source": [
        "###Remove Outliers\n",
        "Some of the reviews are too long or too short. The model requires length of input data to be consistent. So extremely long or short reviews should be eliminated and the rest of reviews should either be truncated or padded with new values to reach the appropriate length."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCqtFa42jAgU",
        "colab_type": "code",
        "outputId": "56b16ac1-f14f-4341-a91d-4fde9ce7d5a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# check for outliers in reviews\n",
        "review_lens = Counter([len(x) for x in reviews_ints])\n",
        "print(\"Zero-length reviews: {}\".format(review_lens[0]))\n",
        "print(\"Maximum review length: {}\".format(max(review_lens)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Zero-length reviews: 1\n",
            "Maximum review length: 2514\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GP9IQPyhnYLx",
        "colab_type": "code",
        "outputId": "99f62397-023d-4238-facb-f142d3f71cfd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "#remove 0-length reviews and respective labels\n",
        "print('Number of reviews before removing outliers: ', len(reviews_ints))\n",
        "\n",
        "# get indices of any reviews with length 0\n",
        "non_zero_idx = [i for i, review in enumerate(reviews_ints) if len(review) != 0]\n",
        "\n",
        "# remove 0-length reviews and their labels\n",
        "reviews_ints = [reviews_ints[ii] for ii in non_zero_idx]\n",
        "encoded_labels = np.array([encoded_labels[ii] for ii in non_zero_idx])\n",
        "\n",
        "print('Number of reviews after removing outliers: ', len(reviews_ints))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of reviews before removing outliers:  25001\n",
            "Number of reviews after removing outliers:  25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeJYM2nTpf6X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#truncate long reviews or pad the short ones with columns of 0 on the left\n",
        "def pad_reviews(reviews_ints, r_length):\n",
        "    \n",
        "    # create a 0-filled 2D array with num_rows=num_reviews & num_cols=r_length\n",
        "    padded_r = np.zeros((len(reviews_ints), r_length), dtype=int)\n",
        "\n",
        "    # for each review, \n",
        "    for i, review_ints in enumerate(reviews_ints):\n",
        "        # fill each row of the 0-filled 2D array with the encoded int values \n",
        "        # of the review. To conserve the 0 values on the left of each row\n",
        "        # when the review is too short start filling from the end\n",
        "        # if the review is too long, just truncated up to r_length \n",
        "        padded_r[i, -len(review_ints):] = np.array(review_ints)[:r_length]\n",
        "    \n",
        "    return padded_r"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dGFkTNxxvc6",
        "colab_type": "text"
      },
      "source": [
        "### Test implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVJUS1HlxzuI",
        "colab_type": "code",
        "outputId": "8a013b89-6b0c-4550-81eb-538788cc7ad3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "# Input size for each review\n",
        "r_length = 200\n",
        "\n",
        "features = pad_reviews(reviews_ints, r_length=r_length)\n",
        "\n",
        "assert len(features)==len(reviews_ints), \"Your features should have as many rows as reviews.\"\n",
        "assert len(features[0])==r_length, \"Each feature row should contain seq_length values.\"\n",
        "\n",
        "# print first 10 word values of the first 20 batches \n",
        "print(features[:20,:10])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[    0     0     0     0     0     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0     0     0]\n",
            " [22382    42 46418    15   706 17139  3389    47    77    35]\n",
            " [ 4505   505    15     3  3342   162  8312  1652     6  4819]\n",
            " [    0     0     0     0     0     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0     0     0]\n",
            " [   54    10    14   116    60   798   552    71   364     5]\n",
            " [    0     0     0     0     0     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0     0     0]\n",
            " [    1   330   578    34     3   162   748  2731     9   325]\n",
            " [    9    11 10171  5305  1946   689   444    22   280   673]\n",
            " [    0     0     0     0     0     0     0     0     0     0]\n",
            " [    1   307 10399  2069  1565  6202  6528  3288 17946 10628]\n",
            " [    0     0     0     0     0     0     0     0     0     0]\n",
            " [   21   122  2069  1565   515  8181    88     6  1325  1182]\n",
            " [    1    20     6    76    40     6    58    81    95     5]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkiFQbPo5yWt",
        "colab_type": "text"
      },
      "source": [
        "### Split data in training, validation and test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HH1_sXGL58M-",
        "colab_type": "code",
        "outputId": "cd262075-0ef8-4525-fb55-1eec4b08f2bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "# 0.8 train - 0.1 validation - 0.1 test\n",
        "split_factor = 0.8\n",
        "\n",
        "split_index = int(len(features) * split_factor)\n",
        "\n",
        "train_data, rest_of_data = features[:split_index], features[split_index:]\n",
        "train_y, rest_of_data_y = encoded_labels[:split_index], encoded_labels[split_index:]\n",
        "\n",
        "\n",
        "test_index = int(len(rest_of_data) * 0.5)\n",
        "\n",
        "valid_data, test_data = rest_of_data[:test_index], rest_of_data[test_index:]\n",
        "val_y, test_y = rest_of_data_y[:test_index], rest_of_data_y[test_index:]\n",
        "\n",
        "print(\"Train set: \\t\\t{}\".format(train_data.shape), \n",
        "      \"\\nValidation set: \\t{}\".format(valid_data.shape),\n",
        "      \"\\nTest set: \\t\\t{}\".format(test_data.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train set: \t\t(20000, 200) \n",
            "Validation set: \t(2500, 200) \n",
            "Test set: \t\t(2500, 200)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbX7X0wr9YhW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "batch_size = 50\n",
        "\n",
        "# convert to Tensor \n",
        "train_set = TensorDataset(torch.from_numpy(train_data), torch.from_numpy(train_y))\n",
        "valid_set = TensorDataset(torch.from_numpy(valid_data), torch.from_numpy(val_y))\n",
        "test_set = TensorDataset(torch.from_numpy(test_data), torch.from_numpy(test_y))\n",
        "\n",
        "# load in batches\n",
        "train_loader = DataLoader(train_set, shuffle=True, batch_size=batch_size)\n",
        "valid_loader = DataLoader(valid_set, shuffle=True, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_set, shuffle=True, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoGDqAqm-uwM",
        "colab_type": "code",
        "outputId": "a70e6efc-8439-445a-9dbe-7815edc31862",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "sample_x, sample_y = dataiter.next()\n",
        "\n",
        "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
        "print('Sample input: \\n', sample_x)\n",
        "print()\n",
        "print('Sample label size: ', sample_y.size()) # batch_size\n",
        "print('Sample label: \\n', sample_y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample input size:  torch.Size([50, 200])\n",
            "Sample input: \n",
            " tensor([[   0,    0,    0,  ...,    4,   11,   18],\n",
            "        [ 281,   21, 1236,  ...,    9,   11,    8],\n",
            "        [  11,   18,   14,  ...,   82,    2,   11],\n",
            "        ...,\n",
            "        [  54,   10,   14,  ...,   93,    8,   61],\n",
            "        [   0,    0,    0,  ...,  164,  104,  544],\n",
            "        [7785,  743,    1,  ...,    6, 7785,  743]])\n",
            "\n",
            "Sample label size:  torch.Size([50])\n",
            "Sample label: \n",
            " tensor([0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
            "        1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0,\n",
            "        0, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klz0MAV9ODTa",
        "colab_type": "text"
      },
      "source": [
        "###Create model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cvryi57nOH-V",
        "colab_type": "code",
        "outputId": "e1f10ce9-ce84-45b9-a8cd-d8af7b7b5bab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Check if GPU is available\n",
        "train_on_gpu=torch.cuda.is_available()\n",
        "\n",
        "if(train_on_gpu):\n",
        "    print('Training on GPU.')\n",
        "else:\n",
        "    print('No GPU available, training on CPU.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on GPU.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeDHhsfoy-MS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class SentimentNet(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n",
        "      \n",
        "        super(SentimentNet, self).__init__()\n",
        "\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_dim = hidden_dim\n",
        "        \n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, \n",
        "                            dropout=drop_prob, batch_first=True)\n",
        "        \n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        \n",
        "        self.fc = nn.Linear(hidden_dim, output_size)\n",
        "        self.sig = nn.Sigmoid()\n",
        "        \n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "      \n",
        "        batch_size = x.size(0)\n",
        "        \n",
        "        x = x.long()\n",
        "        embeds = self.embedding(x)\n",
        "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
        "        \n",
        "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
        "        \n",
        "        out = self.dropout(lstm_out)\n",
        "        out = self.fc(out)        \n",
        "        sig_out = self.sig(out)\n",
        "        \n",
        "        sig_out = sig_out.view(batch_size, -1)\n",
        "        sig_out = sig_out[:, -1] # get last batch of labels\n",
        "        \n",
        "        return sig_out, hidden\n",
        "    \n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "      \n",
        "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
        "        # initialized to zero, for hidden state and cell state of LSTM\n",
        "        weight = next(self.parameters()).data\n",
        "        \n",
        "        if (train_on_gpu):\n",
        "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
        "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
        "        else:\n",
        "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
        "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
        "        \n",
        "        return hidden"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kmz-YSOKvVhe",
        "colab_type": "code",
        "outputId": "2908f1b1-1520-48eb-c959-6e55a827e4cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "# Instantiate the model w/ hyperparams\n",
        "vocab_size = len(w_to_int) + 1 \n",
        "output_size = 1\n",
        "embedding_dim = 400\n",
        "hidden_dim = 256\n",
        "n_layers = 2\n",
        "\n",
        "net = SentimentNet(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
        "\n",
        "print(net)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SentimentNet(\n",
            "  (embedding): Embedding(74073, 400)\n",
            "  (lstm): LSTM(400, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
            "  (dropout): Dropout(p=0.3)\n",
            "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
            "  (sig): Sigmoid()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDF7jlyQvZUL",
        "colab_type": "text"
      },
      "source": [
        "##Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLk9X1Myvctl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr=0.001\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cUNooGGvgnE",
        "colab_type": "code",
        "outputId": "4a11ddb5-344b-4134-8cf1-1b6084e6ea1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "\n",
        "epochs = 4 \n",
        "\n",
        "counter = 0\n",
        "print_every = 100\n",
        "# gradient clipping\n",
        "clip=5 \n",
        "\n",
        "if(train_on_gpu):\n",
        "    net.cuda()\n",
        "\n",
        "net.train()\n",
        "\n",
        "for e in range(epochs):\n",
        "  \n",
        "    h = net.init_hidden(batch_size)\n",
        "    \n",
        "    for inputs, labels in train_loader:\n",
        "        counter += 1\n",
        "\n",
        "        if(train_on_gpu):\n",
        "            inputs, labels = inputs.cuda(), labels.cuda()\n",
        "            \n",
        "        h = tuple([each.data for each in h])\n",
        "        \n",
        "        net.zero_grad()\n",
        "        \n",
        "        output, h = net(inputs, h)\n",
        "        \n",
        "        loss = criterion(output.squeeze(), labels.float())\n",
        "        loss.backward()\n",
        "        # prevent the exploding gradient problem in RNNs / LSTMs.\n",
        "        nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
        "        optimizer.step()\n",
        "        \n",
        "        if counter % print_every == 0:\n",
        "          \n",
        "            val_h = net.init_hidden(batch_size)\n",
        "            val_losses = []\n",
        "            net.eval()\n",
        "            for inputs, labels in valid_loader:\n",
        "              \n",
        "                val_h = tuple([each.data for each in val_h])\n",
        "\n",
        "                if(train_on_gpu):\n",
        "                    inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "                output, val_h = net(inputs, val_h)\n",
        "                val_loss = criterion(output.squeeze(), labels.float())\n",
        "\n",
        "                val_losses.append(val_loss.item())\n",
        "\n",
        "            net.train()\n",
        "            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
        "                  \"Step: {}...\".format(counter),\n",
        "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
        "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/4... Step: 100... Loss: 0.601795... Val Loss: 0.647134\n",
            "Epoch: 1/4... Step: 200... Loss: 0.629885... Val Loss: 0.610831\n",
            "Epoch: 1/4... Step: 300... Loss: 0.617199... Val Loss: 0.701001\n",
            "Epoch: 1/4... Step: 400... Loss: 0.668857... Val Loss: 0.519369\n",
            "Epoch: 2/4... Step: 500... Loss: 0.467429... Val Loss: 0.536550\n",
            "Epoch: 2/4... Step: 600... Loss: 0.265516... Val Loss: 0.495581\n",
            "Epoch: 2/4... Step: 700... Loss: 0.415150... Val Loss: 0.453255\n",
            "Epoch: 2/4... Step: 800... Loss: 0.694688... Val Loss: 0.489844\n",
            "Epoch: 3/4... Step: 900... Loss: 0.303322... Val Loss: 0.454577\n",
            "Epoch: 3/4... Step: 1000... Loss: 0.285727... Val Loss: 0.570366\n",
            "Epoch: 3/4... Step: 1100... Loss: 0.252437... Val Loss: 0.454075\n",
            "Epoch: 3/4... Step: 1200... Loss: 0.148807... Val Loss: 0.414570\n",
            "Epoch: 4/4... Step: 1300... Loss: 0.201714... Val Loss: 0.465686\n",
            "Epoch: 4/4... Step: 1400... Loss: 0.129139... Val Loss: 0.484931\n",
            "Epoch: 4/4... Step: 1500... Loss: 0.211350... Val Loss: 0.526655\n",
            "Epoch: 4/4... Step: 1600... Loss: 0.112922... Val Loss: 0.533203\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnjvXu9zvnQY",
        "colab_type": "text"
      },
      "source": [
        "##Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gnnv7M6vlyj",
        "colab_type": "code",
        "outputId": "10401fdd-5c1c-4271-c9f0-7a7ac3fb254a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "test_losses = [] \n",
        "num_correct = 0\n",
        "\n",
        "h = net.init_hidden(batch_size)\n",
        "\n",
        "net.eval()\n",
        "\n",
        "for inputs, labels in test_loader:\n",
        "  \n",
        "    h = tuple([each.data for each in h])\n",
        "\n",
        "    if(train_on_gpu):\n",
        "        inputs, labels = inputs.cuda(), labels.cuda()\n",
        "        \n",
        "    output, h = net(inputs, h)\n",
        "    \n",
        "    test_loss = criterion(output.squeeze(), labels.float())\n",
        "    test_losses.append(test_loss.item())\n",
        "    \n",
        "    # convert output probabilities to predicted class (0 or 1)\n",
        "    pred = torch.round(output.squeeze())\n",
        "    \n",
        "    correct_tensor = pred.eq(labels.float().view_as(pred))\n",
        "    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
        "    num_correct += np.sum(correct)\n",
        "    \n",
        "    \n",
        "print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n",
        "\n",
        "test_acc = num_correct/len(test_loader.dataset)\n",
        "print(\"Test accuracy: {:.3f}\".format(test_acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.550\n",
            "Test accuracy: 0.783\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtsW1L0_vvTl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# negative test review\n",
        "test_review_neg = 'The worst movie I have seen; acting was terrible and I want my money back. This movie had bad acting and the dialogue was slow.'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmSqMl_2vz8n",
        "colab_type": "code",
        "outputId": "92a5b68b-51ce-4b19-e2a4-e0b5044c9611",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from string import punctuation\n",
        "\n",
        "def tokenize_review(test_review):\n",
        "    test_review = test_review.lower() \n",
        "    test_text = ''.join([c for c in test_review if c not in punctuation])\n",
        "    test_words = test_text.split()\n",
        "    \n",
        "    test_ints = []\n",
        "    test_ints.append([w_to_int[word] for word in test_words])\n",
        "\n",
        "    return test_ints\n",
        "  \n",
        "test_ints = tokenize_review(test_review_neg)\n",
        "print(test_ints)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1, 247, 18, 10, 28, 108, 113, 14, 388, 2, 10, 181, 60, 273, 144, 11, 18, 68, 76, 113, 2, 1, 410, 14, 539]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3v0umiTv3J_",
        "colab_type": "code",
        "outputId": "e607020c-09dd-448d-b2da-b8b8973ab0af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "\n",
        "seq_length=200\n",
        "features = pad_reviews(test_ints, seq_length)\n",
        "\n",
        "print(features)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   1 247  18  10  28\n",
            "  108 113  14 388   2  10 181  60 273 144  11  18  68  76 113   2   1 410\n",
            "   14 539]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HC8QrrnVv6gf",
        "colab_type": "code",
        "outputId": "4bf8a982-4b19-4206-d574-bc3ad488b492",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "feature_tensor = torch.from_numpy(features)\n",
        "print(feature_tensor.size())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 200])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfB30fl7v_Xg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(net, test_review, sequence_length=200):\n",
        "    \n",
        "    net.eval()\n",
        "    test_ints = tokenize_review(test_review)\n",
        "    seq_length=sequence_length\n",
        "    features = pad_reviews(test_ints, seq_length)\n",
        "    feature_tensor = torch.from_numpy(features)\n",
        "    \n",
        "    batch_size = feature_tensor.size(0)\n",
        "    \n",
        "    h = net.init_hidden(batch_size)\n",
        "    \n",
        "    if(train_on_gpu):\n",
        "        feature_tensor = feature_tensor.cuda()\n",
        "        \n",
        "    output, h = net(feature_tensor, h)\n",
        "    \n",
        "    # convert output probabilities to predicted class (0 or 1)\n",
        "    pred = torch.round(output.squeeze()) \n",
        "    print('Prediction value, pre-rounding: {:.6f}'.format(output.item()))\n",
        "    \n",
        "    if(pred.item()==1):\n",
        "        print(\"Positive review detected!\")\n",
        "    else:\n",
        "        print(\"Negative review detected.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lp53x0z0wDBc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# positive test review\n",
        "test_review_pos = 'This movie had the best acting and the dialogue was so good. I loved it.'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vm0hk5SAwHDs",
        "colab_type": "code",
        "outputId": "aabaf9ad-f01b-4fe7-972c-3d71fac82377",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "seq_length=200 \n",
        "\n",
        "predict(net, test_review_neg, seq_length)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction value, pre-rounding: 0.007705\n",
            "Negative review detected.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}